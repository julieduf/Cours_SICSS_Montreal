inspect(dtm_trumptweets[1:5,1:8])
trump_DTM %>% {
wordcloud(.$word, .$n, max.words = 20)
}
?wordcloud()
wordcloud(dtm_trumptweets$word, dtm_trumptweets$n, max.words = 20)
dtm_trumptweets_matrix <- as.matrix(dtm_trumptweets)
dtm_trumptweets_matrix %>% {
wordcloud(.$word, .$n, max.words = 20)
}
dtm_trumptweets_matrix[1:5,1:8]
wordcloud(dtm_trumptweets$word, dtm_trumptweets$n)
wordcloud(dtm_trumptweets_matrix$word, dtm_trumptweets_matrix$n)
wordcloud(dtm_trumptweets_matrix$Terms, dtm_trumptweets_matrix$n)
wordcloud(dtm_trumptweets_matrix[, Terms], dtm_trumptweets_matrix$n)
wordcloud(dtm_trumptweets_matrix[, Terms], dtm_trumptweets_matrix[, n])
wordcloud(dtm_trumptweets_matrix[, Terms], dtm_trumptweets_matrix[n, ])
rm(list = ls())
#install.packages("tidytext")
#install.packages("textdata")
library(tidyverse)
library(tidytext)
library(textdata) #
library(tm)
library(maps)
library(SnowballC)
library(wordcloud)
load(url("https://cbail.github.io/Trump_Tweets.Rdata")) #```{r} I activated this one and commented the following code. The trumptweets <- readRDS("trumptweets.RData") throws error.
trumptweets <- readRDS("../Données/trumptweets.RData")
tidy_trump_tweets <-
trumptweets %>%
select(created_at, text) %>%
unnest_tokens("word", text)     # Tokenise the data
tidy_trump_tweets
head(tidy_trump_tweets, 12)
tidy_trump_tweets %>%
count(word) %>%
arrange(desc(n))
data("stop_words")
# head(stopwords())
head(stop_words)
tidy_trump_tweets <-
tidy_trump_tweets %>%
anti_join(stop_words)
head(tidy_trump_tweets, 20)
tidy_trump_tweets %>%
count(word) %>%
arrange(desc(n))
tidy_trump_tweets <-
tidy_trump_tweets %>%
filter(!grepl("https|t.co|amp|rt", word))
tidy_trump_tweets %>%
count(word) %>%
arrange(desc(n))
tidy_trump_tweets <-
tidy_trump_tweets %>%
filter(!grepl("\\b\\d+\\b", word))
tidy_trump_tweets <-
tidy_trump_tweets %>%
filter(!grepl("https|t.co|amp|rt", word))
tidy_trump_tweets %>%
count(word) %>%
arrange(desc(n))
tidy_trump_tweets <-
tidy_trump_tweets %>%
filter(!grepl("\\b\\d+\\b", word))
tidy_trump_tweets <-
tidy_trump_tweets %>%
mutate(word = gsub("\\s+","", word))
tidy_trump_tweets <-
tidy_trump_tweets %>%
mutate(word = gsub("\\s+","", word))
tidy_trump_tweets$word <- gsub("\\s+","",tidy_trump_tweets$word)
```{r}
tidy_trump_tweets %>%
count(word, sort = TRUE)
tidy_trump_tweets %>%
count(word) %>%
arrange(desc(n))
top_20 <-
tidy_trump_tweets %>%
count(word, sort = TRUE)
top_20 <- top_20[1:20, ]
top_20
ggplot(top_20) +
geom_bar(aes(x = word, y = n, fill = word), stat = "identity") +
theme_minimal() +
theme(axis.text = element_text(angle = 90, hjust = 1)) +
labs(x = "mot", y = "Nombre de fois que le mot apparait dans un tweet") +
guides(fill = FALSE)
tidy_trump_tfidf <-
trumptweets %>%
select(created_at, text) %>%
unnest_tokens("word", text) %>%
# anti_join(stop_words) %>%
count(word, created_at) %>%
bind_tf_idf(word, created_at, n)
tidy_trump_tfidf <-
trumptweets %>%
select(created_at, text) %>%
unnest_tokens("word", text) %>%
# anti_join(stop_words) %>%
count(word, created_at) %>%
bind_tf_idf(word, created_at, n)
top_tfidf <- tidy_trump_tfidf %>%
arrange(desc(n))
top_tfidf <- tidy_trump_tfidf %>%
arrange(desc(n))
top_tfidf
head(top_tfidf$word)
top_tfidf <-
tidy_trump_tfidf %>%
arrange(desc(tf_idf))
top_tfidf
economic_tweets <-
trumptweets %>%
filter(str_detect(text, economic_dictionary))
economic_dictionary <- "economy|unemployment|trade|tariffs|employment"
economic_dictionary1 <- "Togo|Cameroon"
economic_tweets <-
trumptweets %>%
filter(str_detect(text, economic_dictionary))
head(economic_tweets$text)
head(get_sentiments("afinn"), 24)
summary(get_sentiments("afinn"))
head(get_sentiments("bing"), 24)
summary(get_sentiments("bing"))
dictionnaire <- get_sentiments("bing")
trump_tweet_sentiment <-
tidy_trump_tweets %>%
inner_join(dictionnaire) %>%
count(created_at, sentiment)
View(tidy_trump_tweets)
head(trump_tweet_sentiment)
ggplot(trump_tweet_sentiment) +
geom_line(aes(x=created_at, y=n, color=sentiment), size=.5) +
theme_minimal()+
labs(x = "Date", y = "Nombre de publications", title = "Evolution des sentiments") +
#  facet_wrap(~sentiment)+
theme_bw()
library(lubridate)
tidy_trump_tweets <-
tidy_trump_tweets %>%
mutate(date = date(created_at))
trump_tweet_sentiment1 <-
tidy_trump_tweets %>%
inner_join(get_sentiments("bing")) %>%
count(date, sentiment)
ggplot(trump_tweet_sentiment1) +
geom_line(aes(x=date, y=n, color=sentiment), size=.5) +
theme_minimal() +
labs(x = "Date", y = "Nombre de publications", title = "Evolution des sentiments") +
#  facet_wrap(~sentiment)+
theme_bw()
trump_sentiment_negatif <-
tidy_trump_tweets %>%
inner_join(get_sentiments("bing")) %>%
filter(sentiment=="negative") %>%
count(date, sentiment)
trump_sentiment_negatif
trump_sentiment_positif <-
tidy_trump_tweets %>%
inner_join(get_sentiments("bing")) %>%
filter(sentiment=="positive") %>%
count(date, sentiment)
trump_sentiment_positif
trump_sentiment <-
tidy_trump_tweets %>%
inner_join(get_sentiments("bing")) %>%
count(date, sentiment)
trump_sentiment
negatif <-
ggplot(trump_sentiment_negatif) +
geom_line(aes(x = date, y = n), color = "red") +
labs(x = "Date", y = "Fréquence de mots négative dans les tweet de Trump")
negatif
trump_approval <- read.csv("https://projects.fivethirtyeight.com/trump-approval-data/approval_topline.csv")
head(trump_approval)
trump_approval <-
trump_approval %>%
mutate(date = mdy(modeldate))
head(trump_approval)
approval_plot <-
trump_approval %>%
filter(subgroup == "Adults") %>%
#filter(date > min(trump_sentiment_plot$date)) %>%
group_by(date) %>%
summarise(approval = mean(approve_estimate))
head(approval_plot)
approval <-
ggplot(approval_plot) +
geom_line(aes(x = date, y = approval)) +
#theme_minimal()+
labs(x = "Date", y = "% des Américains qui aprouvent Trump")
approval
library(ggpubr)
ggarrange(negatif, approval, nrow = 2)
nrc <- get_sentiments("nrc")
trump_tweet_sentiment_nrc <-
tidy_trump_tweets %>%
inner_join(nrc) %>%
count(date, sentiment)
trump_tweet_sentiment_nrc
tidy_trump_tweets_nrc1 <-
tidy_trump_tweets %>%
inner_join(nrc) %>%
group_by(sentiment) %>%
count() %>%
ungroup()%>%
arrange(desc(sentiment)) %>%
mutate(percentage = round(n/sum(n), 4)*100,
lab.pos = cumsum(percentage)-.5*percentage)
View(tidy_trump_tweets_nrc1)
tidy_trump_tweets_nrc1 <-
tidy_trump_tweets %>%
inner_join(nrc) %>%
group_by(sentiment) %>%
count() %>%
ungroup()%>%
arrange(desc(sentiment)) %>%
mutate(percentage = round(n/sum(n), 4)*100,
lab.pos = cumsum(percentage))
ggplot(data = tidy_trump_tweets_nrc1, aes(x = 2, y = percentage, fill = sentiment))+
geom_bar(stat = "identity")+
coord_polar("y", start = 200) +
geom_text(aes(y = lab.pos, label = paste(percentage,"%", sep = "")), col = "white") +
theme_void() +
#scale_fill_brewer(palette = "Dark2")+
xlim(.5, 2.5) +
ggtitle("Sentiment dans les tweets de Trump")
tidy_trump_tweets_nrc1 <-
tidy_trump_tweets %>%
inner_join(nrc) %>%
group_by(sentiment) %>%
count() %>%
ungroup()%>%
arrange(desc(sentiment)) %>%
mutate(percentage = round(n/sum(n), 4)*100,
lab.pos = cumsum(percentage)-.5*percentage)
ggplot(data = tidy_trump_tweets_nrc1, aes(x = 2, y = percentage, fill = sentiment))+
geom_bar(stat = "identity")+
coord_polar("y", start = 200) +
geom_text(aes(y = lab.pos, label = paste(percentage,"%", sep = "")), col = "white") +
theme_void() +
#scale_fill_brewer(palette = "Dark2")+
xlim(.5, 2.5) +
ggtitle("Sentiment dans les tweets de Trump")
# Effacer l'environnement
rm(list = ls())
# Installer les différents packages
# Charger le packages
library(tidyverse)
library(lubridate)
library(stringr)
library(forcats)
library(modelr)
library(tidytext)
library(tm)
library(maps)
library(SnowballC)
library(wordcloud)
DIR_SOURCE <- system.file("extdata/federalist", package = "qss")
corpus_raw <- VCorpus(DirSource(directory = DIR_SOURCE, pattern = "fp"))
corpus_raw
trumptweets <- readRDS("../Données/trumptweets.Rdata")
View(trumptweets)
tidy_trump_tweets <-
trumptweets %>%
select(created_at, text) %>%
unnest_tokens("word", text)
library(tidyverse)
library(tidyverse)
library(tidytext)
library(textdata)
library(tm)
library(maps)
library(SnowballC)
library(wordcloud)
library(topicmodels)
tidy_trump_tweets <-
trumptweets %>%
select(created_at, text) %>%
unnest_tokens("word", text)
View(tidy_trump_tweets)
View(tidy_trump_tweets)
tidy_trump_tweets <-
tidy_trump_tweets %>%
anti_join(stop_words)
tidy_trump_tweets <-
tidy_trump_tweets[-grep("https|t.co|amp|rt", tidy_trump_tweets$word), ]
tidy_trump_tweets <- tidy_trump_tweets[-grep("\\b\\d+\\b", tidy_trump_tweets$word),]
tidy_trump_tweets$word <- gsub("\\s+","",tidy_trump_tweets$word)
tidy_trump_tweets %>%
count(word) %>%
arrange(desc(n))
trump_tweets_dtm <-
tidy_trump_tweets %>%
count(created_at, word)
View(trump_tweets_dtm)
trump_tweets_dtm <-
tidy_trump_tweets %>%
count(created_at, word) %>%
cast_dtm(created_at, word, n)
inspect(trump_tweets_dtm[1:5,1:8])
inspect(trump_tweets_dtm[1:5,1:6])
trump_tweet_lda <- LDA(trump_tweets_dtm, k = 3, control = list(seed = 3425))
trump_tweet_lda
tt_topics <- tidy(trump_tweet_lda, matrix = "beta")
tt_topics
tt_top_term <-
tt_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, desc(beta))
tt_top_term
tt_top_term %>%
#mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(x = term, y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
#coord_flip() +
facet_wrap(~ topic, scales = "free")
tt_top_term %>%
#mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(x = term, y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~ topic, scales = "free")
tt_top_term %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(x = term, y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~ topic, scales = "free")
trump_tweet_lda <- LDA(trump_tweets_dtm, k = 5, control = list(seed = 3425))
tt_topics <- tidy(trump_tweet_lda, matrix = "beta")
tt_topics
tt_top_term <-
tt_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, desc(beta))
tt_top_term %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(x = term, y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~ topic, scales = "free")
rm(list = ls())
library(tidyverse)
library(lubridate)
library(stringr)
library(forcats)
library(modelr)
library(tm)
library(SnowballC)
library(tidytext)
library(wordcloud)
library(qss)
DIR_SOURCE <- system.file("extdata/federalist", package = "qss")
corpus_raw <- VCorpus(DirSource(directory = DIR_SOURCE, pattern = "fp"))
corpus_raw
View(corpus_raw)
inspect(corpus_raw[1:5, 1:4])
corpus_raw[[1]]
corpus_raw[[1]][1]
corpus_raw[[1]][1]
corpus_tidy <- tidy(corpus_raw, "corpus")
View(corpus_tidy)
corpus_tidy <- corpus_tidy %>%
mutate(id_num1 = str_sub(id, 3, 4),
id_num = as.integer(str_extract(id, pattern = "\\d+")))
View(corpus_tidy)
corpus_tidy_text <- corpus_tidy %>%
select(id_num, text) %>%
unnest_tokens("word", text)
View(corpus_tidy_text)
corpus_tidy_text <-
corpus_tidy_text %>%
anti_join(stop_words)
corpus_tidy_text <-
corpus_tidy_text %>%
filter(!grepl("\\b\\d+\\b", word))
corpus_tidy_text <-
corpus_tidy_text %>%
mutate(word = gsub("\\s", "", word))
corpus_tidy_text <-
corpus_tidy_text %>%
#mutate_at("word", funs(wordStem((.), language = "en")))
mutate(word_st = wordStem(word, language = "en"))
View(corpus_tidy_text)
corpus_tidy_text <-
corpus_tidy_text %>%
mutate_at("word", funs(wordStem((.), language = "en")))
doc12 <- corpus_tidy_text %>%
filter(id_num == 12) %>%
group_by(word) %>%
count() %>%
arrange(desc(n))
View(doc12)
doc12_10 <- doc12[1:10, ]
View(doc12_10)
graph_doc <- function(donnee){
ggplot(donnee) +
geom_col(aes(x = reorder(word, desc(n)), y = n, fill = word), show.legend = FALSE) +
labs(x = "Word") +
coord_flip() #+
#guides(color = FALSE)
}
graph_doc(doc12_10)
corpus_tidy_text_tfidf <- corpus_tidy_text %>%
count(word, id_num) %>%
bind_tf_idf(word, id_num, n)
View(corpus_tidy_text_tfidf)
doc12_idf <-
corpus_tidy_text_tfidf %>%
filter(id_num == 12) %>%
arrange(desc(tf_idf))
doc12_idf_10 <- doc12_idf[1:10, ]
graph_doc(doc12_idf_10)
doc12_idf <-
corpus_tidy_text_tfidf %>%
filter(id_num == 24) %>%
arrange(desc(tf_idf))
doc12_idf_10 <- doc12_idf[1:10, ]
graph_doc(doc12_idf_10)
filter(corpus_tidy_text_tfidf, id_num == 12) %>% {
wordcloud(.$word, .$n, max.words = 20)
}
filter(corpus_tidy_text_tfidf, id_num == 12) %>% {
wordcloud(.$word, .$tf_idf, max.words = 20)
}
View(corpus_tidy_text_tfidf)
hm <- c(1, 6:9, 11:13, 15:17, 21:36, 59:61, 65:85)
corpus_tidy_text_tfidf <-
corpus_tidy_text_tfidf %>%
mutate(Author = if_else(id_num %in% hm, "Hamilton", "NA"))
Hamilton <- corpus_tidy_text_tfidf %>%
filter(Author == "Hamilton")
View(Hamilton)
View(Hamilton)
Hamilton_dtm <- Hamilton %>%
cast_dtm(id_num, word, tf_idf)
inspect(Hamilton_dtm[1:5, 2:7])
inspect(Hamilton_dtm[7:10, 2:7])
CLUSTERS <- 4
kmean_out <-
Hamilton_dtm %>%
kmeans(centers = CLUSTERS, nstart = 10)
hamilton_words <-
tibble(word = colnames(Hamilton_dtm))
hamilton_words <- bind_cols(hamilton_words, as_tibble(t(kmean_out$centers)))
View(hamilton_words)
top_word <-
hamilton_words %>%
pivot_longer(cols = c("1":"4"), "cluster", "value")
View(top_word)
top_word <-
hamilton_words %>%
pivot_longer(cols = c("1":"4"), "cluster", "value") %>%
group_by(cluster) %>%
top_n(10, value)
ggplot(top_word %>% filter(cluster == 1)) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip()
ggplot(top_word %>% filter(cluster == 2)) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip()
facet_wrap(~cluster)
ggplot(top_word) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip()
ggplot(top_word) +
geom_col(aes(x = reorder(word, desc(value)), y = value)) +
coord_flip() +
facet_wrap(~cluster)
top_word_summary <-
top_word %>%
group_by(cluster) %>%
summarise(top_word = str_c(word, collapse = ", "))
top_word_summary
library(topicmodels)
View(Hamilton)
Hamilton_dtm_tf <- Hamilton %>%
cast_dtm(id_num, word, n)
inspect(Hamilton_dtm[1:5, 2:6])
topic_hamilton_lda <- LDA(Hamilton_dtm_tf, k = 4, control = list(seed = 2342))
topic_hamilton_data <- tidy(topic_hamilton_lda, matrix = "beta")
topic_hamilton_data
tt_top_term <-
topic_hamilton_data %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, desc(beta))
tt_top_term
tt_top_term %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(x = term, y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~ topic, scales = "free")
View(tt_top_term)
View(tt_top_term)
tt_top_term %>%
filter(term != "corpus") %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(x = term, y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
facet_wrap(~ topic, scales = "free")
