---
title: 'Création bd des médias'
author: "Alexandre Lamont"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
---


<!--
- Je ne vois pas les publications de Legault
- Je ne vois pas les publications de la Presse et du Devoir
- Ce qui serait interessant et qu'on n'a pas, c'est de voir parmi l'ensemble des publications de Legault, combien porte sur le sujet que nous étudions
- Je souhaite plutôt qu'on collecte toutes les publications des trois politiciens ainsi que des journaux depuis l'élection de Francçois Legault. On fera nos tris après.

Ressources rencontrées

https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1


GND parle de Mamadou Konaté alors que François Legault n'en parle pas.
https://montreal.ctvnews.ca/judge-grants-stay-of-deportation-for-quebec-guardian-angel-mamadou-konate-1.5671062


-->


## Mes suggestions

- Charger les packages

```{r}

rm(list = ls())
#install.packages("tidystopwords")
library(tidyverse)
library(readxl)
library(lubridate)
library(summarytools)
library(gtsummary)
library(tidytext)
library(tidystopwords)  # Stop word


```

- Autres données

```{r}

fbcomments <- read_csv("FBComment_updateC.csv")
fbposts <- read_delim("FBPost_updateC.csv", delim = "\t")


```



- Charger les données de Alexandre

```{r}

Legault <- read_excel("legault_2258590544197963.xlsx")
Legault <-
  Legault %>% 
  mutate(Nom = "Legault")

GND <- read_excel("gnd_1389794314713133.xlsx")
GND <-
  GND %>% 
  mutate(Nom = "Nadeau")

Jdm <- read_excel("jdm_1844588875635766.xlsx")
Jdm <-
  Jdm %>% 
  mutate(Nom = "Journal de Montréal")

## Fusion des fichiers

observatoire <- bind_rows(Legault, GND, Jdm)

freq(observatoire$Nom)

```


## Évolution des posts (commentaires)


```{r}


observatoire <-
  observatoire %>% 
  mutate(date_comments = date(created_time)) 

Nbre_comments <-
  observatoire %>% 
  group_by(date_comments, Nom) %>% 
  count()

ggplot(Nbre_comments) +
  geom_line(aes(x = date_comments, y = n, group = Nom, color = Nom)) +
  labs(title = "Nombre de commentaires selon les acteurs") +
  theme_bw()

```


- On remarque que les données ne concordent pas sur la même période. 
- Il faudra refaire la collecte des données




## Détection des commentaires tendancieux

```{r}

# "Nous|nous|eux|Eux|nos|Nos|leur|Leur|nôtre|notre|Notre|les|vs|Vs|NOTRE|NOS|mon|ma|MON|MA|autres")

nous_autres <- "nous autres | eux | nôtre | vous"
discriminatoires <- 
immigrants <- "intégri|Intégri|extré|Extré|immi|Immi|réfugi|Réfugi|refug|Refug|racis|racia|Raci|autochton|envahi|arriva|import|bs|BS|Bs|syrien|haitien|haïtien|bandit|kippa|Kippa|hidjab|Hidjab"

#Nous_autres <- list(Nous_autres = c("nous autres" | "eux" | "nôtre"))

observatoire <-
  observatoire %>% 
  mutate(nous_autres = if_else(str_detect(message, nous_autres), 1, 0),
         immigrants = if_else(str_detect(message, immigrants), 1, 0))
  

```


- Il faut mieux créer les éléments des groupes. On peut discuter de cela

## Les indicateurs que tu as calculé

```{r}


# Crée une variable indicatrice

observatoire <-
  observatoire %>% 
  mutate(num1 = if_else(!is.na(message), 1, NA_real_)) 

# Par date
indicateurs <-
  observatoire %>% 
  group_by(date_comments, Nom) %>% 
  summarise(total_comment = sum(num1, na.rm = TRUE),
            total_nous_autres = sum(nous_autres, na.rm = TRUE),
            total_immigrants = sum(immigrants, na.rm = TRUE)) %>% 
  mutate(prop_autres = total_nous_autres / total_comment*100,
         prop_immigrants = total_immigrants / total_comment*100)

# Global
indicateurs_global <-
  observatoire %>% 
  group_by(Nom) %>% 
  summarise(total_comment = sum(num1, na.rm = TRUE),
            total_nous_autres = sum(nous_autres, na.rm = TRUE),
            total_immigrants = sum(immigrants, na.rm = TRUE)) %>% 
  mutate(prop_autres = total_nous_autres / total_comment*100,
         prop_immigrants = total_immigrants / total_comment*100)  

```

- Graphique à partir de ces données

```{r}

indicateurs_global_long <-
  indicateurs_global %>% 
  pivot_longer(cols = c(prop_autres, prop_immigrants), names_to = "Indicateurs", values_to = "Proportion") %>% 
#  mutate(Indicateurs = str_trunc(Indicateurs, width = 5, side = c("left"))) %>% 
    mutate(Indicateurs = str_remove(Indicateurs, pattern = "prop_"))


ggplot(indicateurs_global_long) +
  geom_col(aes(x = Nom, y = Proportion, fill = Indicateurs, group = Indicateurs), position = "dodge") +
  labs(title = "Proportion des commentaires qui contiennent les tendances décrites")


```

- Cette analyse est mieux d'être faite sur les publications des différents acteurs et pas forcément sur les commentaires

## Nuage des mots


```{r}

tidy_observatoire <- 
  observatoire %>% 
  select(date_comments, Nom, message) %>% 
  unnest_tokens("mots", message)     # Tokenise the data
  
tidy_observatoire  

tidy_observatoire %>% 
  count(mots) %>% 
  arrange(desc(n))

# Stop word

# get french stopwords based on ud language model
#list_supported_languages()
french_stopswords <- generate_stoplist(language = "French")
french_stopswords
french_stopswords <- data_frame(mots = french_stopswords, stringsAsFactors = FALSE)
french_stopswords

class(french_stopswords$mots)

data("stop_words")
head(stopwords(), 15)

tidy_observatoire <- 
  tidy_observatoire %>% 
  anti_join(french_stopswords)

tidy_observatoire %>% 
  count(mots) %>% 
  arrange(desc(n))

## Enlever d'autres mots

autres_mots <- data.frame(mots = c("pas", "c'est", "m", "mr", "aussi", "c"))

tidy_observatoire <- 
  tidy_observatoire %>% 
  anti_join(autres_mots)

# Enlever les chiffres

tidy_observatoire <- tidy_observatoire[-grep("\\b\\d+\\b", tidy_observatoire$mots),]


# Enlever les espaces
tidy_observatoire$mots <- gsub("\\s+","",tidy_observatoire$mots)    

# Stemming
library(SnowballC)

tidy_observatoire <- tidy_observatoire %>%
  mutate_at("mots", funs(wordStem((.), language="fr")))

# Document-term matrix
tidy_observatoire_DTM<-
  tidy_observatoire %>%
  count(date_comments, mots) %>%
  cast_dtm(date_comments, mots, n)

inspect(tidy_observatoire_DTM[1:5, 1:8])

tidy_observatoire %>% 
  count(mots, sort = TRUE)

tidy_observatoire %>%          # Same as previously but with arrange
  count(mots) %>% 
  arrange(desc(n))

# Graphique des 20 mots les plus importants

top20_nom <-
  tidy_observatoire %>% 
  group_by(Nom) %>% 
  count(mots, sort = TRUE) %>% 
  top_n(20)

#  group_by(Nom) %>% 
#  filter(n >= quantile(n, probs = 0.99))




  

freq(top20_nom$Nom)
  
top_20 <- 
  tidy_observatoire %>% 
  group_by(Nom) %>% 
  count(mots, sort = TRUE) 

top_20 <- 
  #group_by(Nom) %>% 
  top_20[1:20, ]    
  
top_20  


#graph_f <- function(data, acteur){
#  ggplot(data %>% filter(data$Nom == data$acteur)) +
#  geom_col(aes(x = reorder(mots, desc(n)), y = n, fill = mots)) +
 # facet_wrap(~Nom, ncol = 1) +
#  coord_flip() +
#  theme(axis.text = element_text(angle = 90, hjust = 1)) +
#  labs(title =  "Mots les plus importants", x = "Mots") +
#  guides(fill = FALSE) +
#  theme_bw()
#}

#graph_legault <- graph_f(top20_nom, Legault) 
#graph_legault

graph_legault <- 
  ggplot(top20_nom %>% filter(Nom == "Legault")) +
  geom_col(aes(x = reorder(mots, desc(n)), y = n, fill = mots)) +
  facet_wrap(~Nom, ncol = 1) +
  coord_flip() +
  theme(axis.text = element_text(angle = 90, hjust = 1)) +
  labs(title =  "Mots les plus importants", x = "Mots") +
  guides(fill = FALSE) +
  theme_bw()
graph_legault


graph_nadeau <- 
  ggplot(top20_nom %>% filter(Nom == "Nadeau")) +
  geom_col(aes(x = reorder(mots, desc(n)), y = n, fill = mots)) +
  facet_wrap(~Nom, ncol = 1) +
  coord_flip() +
  theme(axis.text = element_text(angle = 90, hjust = 1)) +
  labs(title =  "Mots les plus importants", x = "Mots") +
  guides(fill = FALSE) +
  theme_bw()
graph_nadeau



graph_jdm <- 
  ggplot(top20_nom %>% filter(Nom == "Journal de Montréal")) +
  geom_col(aes(x = reorder(mots, desc(n)), y = n, fill = mots)) +
  facet_wrap(~Nom, ncol = 1) +
  coord_flip() +
  theme(axis.text = element_text(angle = 90, hjust = 1)) +
  labs(title =  "Mots les plus importants", x = "Mots") +
  guides(fill = FALSE) +
  theme_bw()
graph_jdm


```



Load
---
```{r, echo=F}
library(tidyverse)
library (readxl)
```


test
---

Test1: Juste les "nous, eux, nos, leurs"
Test2: Juste les posts nommant "l'autre"
Test3: Avoir au moins 2 commentaires ou 2 like
Test4: Réussir 2 des 3 tests

4 nombre par test:
-Nombre de commentaires
-% de commentaires sur nb de commentaires totaux
-Nombre de commentaires discriminatoires
-% de commentaires discriminatoires sur commentaire discriminatories totaux


<!--
Ici, tu fais la même chose 3 fois. Ce n'est pas efficace.
Actuellement, tu utilises R comme une calculatrice. Et tu recopies à la main ce que tu fais.
Tu dois automatiser tout le processus le plus possible


-->


Post de 3101 commentaires
```{r}
Legault <- read_excel("legault_2258590544197963.xlsx")
Commentaires  <- Legault %>% 
  filter (is.na(object_key)==F) %>% 
  filter(duplicated(message)==F) %>% 
  filter (is.na(message)==F)%>% 
  select(id, parent_id, level, message,  like_count, comment_count)

Commentaires <- Commentaires %>% 
  mutate (nb_mot = str_count(message, '\\w+'))

test1 <- Commentaires %>% 
  filter (str_detect(message, c("Nous|nous|eux|Eux|nos|Nos|leur|Leur|nôtre|notre|Notre|les|vs|Vs|NOTRE|NOS|mon|ma|MON|MA|autres")))

test3 <- Commentaires %>% 
  filter (like_count >1 | comment_count >1)

test2 <- Commentaires %>% filter(str_detect(message, "intégri|Intégri|extré|Extré|immi|Immi|réfugi|Réfugi|refug|Refug|racis|racia|Raci|autochton|envahi|arriva|import|bs|BS|Bs|syrien|haitien|
                                   haïtien|bandit|kippa|Kippa|hidjab|Hidjab"))

Commentaires <- Commentaires %>% mutate (test1 = id %in% test1$id)  %>% mutate (test2 = id %in% test2$id) %>% mutate (test3 = id %in% test3$id)

Commentaires <- Commentaires  %>% mutate (test4 = test1+test2+test3) 
test4 <- Commentaires %>% filter (test4>=2)

id_discriminatoire <- c(531, 691, 823, 859, 1130, 1200, 1605, 2231, 2748, 3242, 3334, 3343)


discriminatoire <- Commentaires %>% filter (id %in% id_discriminatoire)

"Total"
(count(Commentaires))$n #numbre de commentaires
100 #pourcentage du total
12#nombre de commentaire discriminatoire
100 #pourcentage de commentaires discriminatoire
"test1"
(count(test1))$n
(count(test1))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test1$id)
sum(id_discriminatoire %in% test1$id)/12*100
"test2"
(count(test2))$n
(count(test2))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test2$id)
sum(id_discriminatoire %in% test2$id)/12*100
"test3"
(count(test3))$n
(count(test3))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test3$id)
sum(id_discriminatoire %in% test3$id)/12*100
"test4"
(count(test4))$n
(count(test4))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test4$id)
sum(id_discriminatoire %in% test4$id)/12*100
"Mots moyen par commentaire (total)"
mean(Commentaires$nb_mot)
"Mots moyen par commentaire (test4)"
mean(test4$nb_mot)
"Mots moyen par commentaire discriminatoire"
mean(discriminatoire$nb_mot)
```


Post de 3101 commentaires


```{r}
GND <- read_excel("gnd_1389794314713133.xlsx")
Commentaires  <- Legault %>% filter (is.na(object_key)==F) %>% filter(duplicated(message)==F) %>% filter (is.na(message)==F)%>% select(id, parent_id, level, message,  like_count, comment_count)

Commentaires <- Commentaires %>% mutate (nb_mot = str_count(message, '\\w+'))

test1 <- Commentaires %>% filter (str_detect(message, c("Nous|nous|eux|Eux|nos|Nos|leur|Leur|nôtre|notre|Notre|les|vs|Vs|NOTRE|NOS|mon|ma|MON|MA|autres")))
test3 <- Commentaires %>% filter (like_count >1 | comment_count >1)
test2 <- Commentaires %>% filter(str_detect(message, "intégri|Intégri|extré|Extré|immi|Immi|réfugi|Réfugi|refug|Refug|racis|racia|Raci|autochton|envahi|arriva|import|bs|BS|Bs|syrien|haitien|
                                   haïtien|bandit|kippa|Kippa|hidjab|Hidjab"))

Commentaires <- Commentaires %>% mutate (test1 = id %in% test1$id)  %>% mutate (test2 = id %in% test2$id) %>% mutate (test3 = id %in% test3$id)
Commentaires <- Commentaires  %>% mutate (test4 = test1+test2+test3) 
test4 <- Commentaires %>% filter (test4>=2)

id_discriminatoire <- c(20,39,128,153,207,227,295,303)


discriminatoire <- Commentaires %>% filter (id %in% id_discriminatoire)

"Total"
(count(Commentaires))$n #numbre de commentaires
100 #pourcentage du total
8#nombre de commentaire discriminatoire
100 #pourcentage de commentaires discriminatoire
"test1"
(count(test1))$n
(count(test1))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test1$id)
sum(id_discriminatoire %in% test1$id)/8*100
"test2"
(count(test2))$n
(count(test2))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test2$id)
sum(id_discriminatoire %in% test2$id)/8*100
"test3"
(count(test3))$n
(count(test3))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test3$id)
sum(id_discriminatoire %in% test3$id)/8*100
"test4"
(count(test4))$n
(count(test4))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test4$id)
sum(id_discriminatoire %in% test4$id)/8*100
"Mots moyen par commentaire (total)"
mean(Commentaires$nb_mot)
"Mots moyen par commentaire (test4)"
mean(test4$nb_mot)
"Mots moyen par commentaire discriminatoire"
mean(discriminatoire$nb_mot)
```


Post de 123 commentaires

```{r}
Jdm <- read_excel("jdm_1844588875635766.xlsx")
Commentaires  <- Jdm %>% filter (is.na(object_key)==F) %>% filter(duplicated(message)==F) %>% filter (is.na(message)==F)%>% select(id, parent_id, level, message,  like_count, comment_count)

Commentaires <- Commentaires %>% mutate (nb_mot = str_count(message, '\\w+'))

test1 <- Commentaires %>% filter (str_detect(message, c("Nous|nous|eux|Eux|nos|Nos|leur|Leur|nôtre|notre|Notre|les|vs|Vs|NOTRE|NOS|mon|ma|MON|MA|autres")))
test3 <- Commentaires %>% filter (like_count >1 | comment_count >1)
test2 <- Commentaires %>% filter(str_detect(message,"intégri|Intégri|extré|Extré|immi|Immi|réfugi|Réfugi|islam|Islam|refug|Refug|racis|racia|Raci|autochton|envahi|arriva|import|bs|BS|Bs|syrien|haitien|haïtien|bandit|parasit|esti|crosseur|pourri|illéga|étrang|etrang"))

Commentaires <- Commentaires %>% mutate (test1 = id %in% test1$id)  %>% mutate (test2 = id %in% test2$id) %>% mutate (test3 = id %in% test3$id)
Commentaires <- Commentaires  %>% mutate (test4 = test1+test2+test3) 
test4 <- Commentaires %>% filter (test4>=2)

id_discriminatoire <- c(2,13,14,24,31,68,84,105)


discriminatoire <- Commentaires %>% filter (id %in% id_discriminatoire)

"Total"
(count(Commentaires))$n #numbre de commentaires
100 #pourcentage du total
8 #nombre de commentaire discriminatoire
100 #pourcentage de commentaires discriminatoire
"test1"
(count(test1))$n
(count(test1))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test1$id)
sum(id_discriminatoire %in% test1$id)/8*100
"test2"
(count(test2))$n
(count(test2))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test2$id)
sum(id_discriminatoire %in% test2$id)/8*100
"test3"
(count(test3))$n
(count(test3))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test3$id)
sum(id_discriminatoire %in% test3$id)/8*100
"test4"
(count(test4))$n
(count(test4))$n/(count(Commentaires))$n*100
sum(id_discriminatoire %in% test4$id)
sum(id_discriminatoire %in% test4$id)/8*100
"Mots moyen par commentaire (total)"
mean(Commentaires$nb_mot)
"Mots moyen par commentaire (test4)"
mean(test4$nb_mot)
"Mots moyen par commentaire discriminatoire"
mean(discriminatoire$nb_mot)
```
